per_device_train_batch_size:  2
gradient_accumulation_steps:  4
warmup_steps:  10
max_steps:  100
learning_rate: 1e-3
fp16: true
lr_scheduler_type: "cosine"
logging_steps: 5
output_dir: "default"
save_steps: 5
save_total_limit: 3
optim: "adamw"